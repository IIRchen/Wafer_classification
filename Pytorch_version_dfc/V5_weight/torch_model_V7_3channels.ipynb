{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T02:20:17.644266Z",
     "start_time": "2024-06-17T02:20:17.635023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeformableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 bias=False):\n",
    "        super(DeformableConv2d, self).__init__()\n",
    "\n",
    "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
    "\n",
    "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
    "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.offset_conv = nn.Conv2d(in_channels,\n",
    "                                     2 * kernel_size[0] * kernel_size[1],\n",
    "                                     kernel_size=kernel_size,\n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding,\n",
    "                                     dilation=self.dilation,\n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
    "\n",
    "        self.modulator_conv = nn.Conv2d(in_channels,\n",
    "                                        1 * kernel_size[0] * kernel_size[1],\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride,\n",
    "                                        padding=self.padding,\n",
    "                                        dilation=self.dilation,\n",
    "                                        bias=True)\n",
    "\n",
    "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
    "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
    "\n",
    "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=self.padding,\n",
    "                                      dilation=self.dilation,\n",
    "                                      bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = self.offset_conv(x)\n",
    "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
    "        x = torchvision.ops.deform_conv2d(input=x,\n",
    "                                          offset=offset,\n",
    "                                          weight=self.regular_conv.weight,\n",
    "                                          bias=self.regular_conv.bias,\n",
    "                                          padding=self.padding,\n",
    "                                          mask=modulator,\n",
    "                                          stride=self.stride,\n",
    "                                          dilation=self.dilation)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.attention(x)\n",
    "        return x * attention\n",
    "    \n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.sam = SAM(bias=False)\n",
    "        self.cam = CAM(channels=self.channels, r=self.r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cam(x)\n",
    "        output = self.sam(output)\n",
    "        return output + x\n",
    "    \n",
    "    \n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
    "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        b, c, _, _ = x.size()\n",
    "        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n",
    "        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n",
    "        output = linear_max + linear_avg\n",
    "        output = F.sigmoid(output) * x\n",
    "        return output\n",
    "    \n",
    "class SAM(nn.Module):\n",
    "    def __init__(self, bias=False):\n",
    "        super(SAM, self).__init__()\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = torch.max(x,1)[0].unsqueeze(1)\n",
    "        avg = torch.mean(x,1).unsqueeze(1)\n",
    "        concat = torch.cat((max,avg), dim=1)\n",
    "        output = self.conv(concat)\n",
    "        output = F.sigmoid(output) * x \n",
    "        return output "
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Paper_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Paper_model, self).__init__()\n",
    "        self.layer1 = DeformableConv2d(3, 32, bias=True)\n",
    "        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.attention1 = CBAM(32, r=2)\n",
    "        self.bn1 = nn.LayerNorm([32, 52, 52])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.layer3 = DeformableConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.attention2 = CBAM(64, r=2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.bn2 = nn.LayerNorm([64, 26, 26])\n",
    "        \n",
    "        self.layer5 = DeformableConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.attention3 = CBAM(128, r=2)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bn3 = nn.LayerNorm([128, 13, 13])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.gelu(x) \n",
    "        x = self.attention1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.gelu(x) \n",
    "        x = self.attention2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.gelu(x) \n",
    "        x = self.attention3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dcn_model = Paper_model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(dcn_model.parameters(), lr=0.001)\n",
    "print(dcn_model)"
   ],
   "metadata": {
    "id": "QezBSWfrbGfu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718528189111,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "Theovin Lautan",
      "userId": "17106006947934370905"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T02:42:36.419769Z",
     "start_time": "2024-06-17T02:42:36.403276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper_model(\n",
      "  (layer1): DeformableConv2d(\n",
      "    (offset_conv): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (modulator_conv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (regular_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention1): CBAM(\n",
      "    (sam): SAM(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (cam): CAM(\n",
      "      (linear): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn1): LayerNorm((32, 52, 52), eps=1e-05, elementwise_affine=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer3): DeformableConv2d(\n",
      "    (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention2): CBAM(\n",
      "    (sam): SAM(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (cam): CAM(\n",
      "      (linear): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn2): LayerNorm((64, 26, 26), eps=1e-05, elementwise_affine=True)\n",
      "  (layer5): DeformableConv2d(\n",
      "    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (attention3): CBAM(\n",
      "    (sam): SAM(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (cam): CAM(\n",
      "      (linear): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn3): LayerNorm((128, 13, 13), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "class WaferDataset(Dataset):\n",
    "    def __init__(self, img_array, label_array):\n",
    "        self.img_array = img_array\n",
    "        self.label_array = label_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.from_numpy(self.img_array[idx]).float()\n",
    "        if img.ndim == 2:  # If the image is grayscale\n",
    "            img = img.unsqueeze(0).repeat(3, 1, 1)  # Repeat the single channel 3 times\n",
    "        elif img.ndim == 3:  # If the image is already multi-channel but in [H, W, C] format\n",
    "            img = img.permute(2, 0, 1)  # Rearrange from [H, W, C] to [C, H, W]\n",
    "        label = torch.from_numpy(self.label_array[idx]).float()\n",
    "        return img, label\n",
    "\n",
    "# 加载数据\n",
    "data = np.load('D:\\DY\\深度學習\\DeepLearning_project-20240501T123840Z-001\\DeepLearning_project\\Dataset\\images_3chnl.npz') # V3_dataset.npz\n",
    "img_array = data['arr_0']\n",
    "label_array = data['arr_1']\n",
    "\n",
    "# 创建数据集\n",
    "wafer_dataset = WaferDataset(img_array, label_array)\n",
    "\n",
    "# 设置划分比例\n",
    "val_split = 0.2\n",
    "dataset_size = len(wafer_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "val_size = int(np.floor(val_split * dataset_size))\n",
    "train_indices, val_indices = indices[val_size:], indices[:val_size]\n",
    "\n",
    "# 创建训练集和验证集的 SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=val_sampler)\n"
   ],
   "metadata": {
    "id": "NwFDoOGQsyRn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718528262293,
     "user_tz": -480,
     "elapsed": 3428,
     "user": {
      "displayName": "Theovin Lautan",
      "userId": "17106006947934370905"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T02:41:47.097184Z",
     "start_time": "2024-06-17T02:41:46.498893Z"
    }
   },
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T02:26:30.123076Z",
     "start_time": "2024-06-17T02:26:30.119808Z"
    }
   },
   "cell_type": "code",
   "source": "img_array.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121648, 52, 52)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 创建数据集\n",
    "wafer_dataset = WaferDataset(img_array, label_array)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 使用数据加载器进行训练\n",
    "# 创建模型实例\n",
    "paper_model = Paper_model()\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(paper_model.parameters(), lr=0.001)  # 可以调整学习率\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 将模型移动到设备上\n",
    "paper_model.to(device)\n",
    "\n",
    "# 加载数据集的代码\n",
    "\n",
    "# 创建数据加载器，并将数据移动到设备上\n",
    "dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader = [(imgs.to(device), labels.to(device)) for imgs, labels in dataloader]\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "def caculate_acc_num(outputs,labels):\n",
    "  acc_num = 0\n",
    "  predicted = (outputs > 0.5).float()\n",
    "  #print(outputs.shape)\n",
    "  for idx in range(predicted.shape[0]):\n",
    "    #print(\"Predicted : \",predicted[idx])\n",
    "    #print(\"Labels : \",labels[idx])\n",
    "    if torch.allclose(predicted[idx], labels[idx]):\n",
    "      acc_num += 1\n",
    "\n",
    "  return acc_num\n",
    "# 使用数据加载器进行训练\n",
    "for epoch in range(num_epochs):\n",
    "    train_acc_num = 0\n",
    "    total_train = 0\n",
    "    train_loss = 0\n",
    "    for imgs, labels in tqdm(train_dataloader):\n",
    "        # 清除梯度\n",
    "        optimizer.zero_grad()\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = paper_model(imgs)\n",
    "        total_train += imgs.shape[0]\n",
    "        train_acc_num += caculate_acc_num(outputs,labels)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "        # 随机选择一笔数据打印其标签和预测值\n",
    "        #idx = random.randint(0, len(labels) - 1)\n",
    "        #print(f'Label: {labels[idx]}, Prediction: {(outputs[idx] > 0.5).float()}')\n",
    "\n",
    "    val_acc_num = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0\n",
    "    for imgs, labels in tqdm(val_dataloader):\n",
    "        # 前向传播\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = paper_model(imgs)\n",
    "        total_val += imgs.shape[0]\n",
    "        val_acc_num += caculate_acc_num(outputs, labels)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 每个 epoch 结束后打印损失\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {(train_loss/total_train):.4f} , Acc : {(train_acc_num/total_train):.4f}')\n",
    "    print(f'Val_loss: {(val_loss/total_val):.4f}, Val_Acc: {(val_acc_num/total_val):.4f}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDItKcRaga9G",
    "outputId": "a719e04c-f2d9-471a-b4d4-349d8faf20b7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718528943889,
     "user_tz": -480,
     "elapsed": 678136,
     "user": {
      "displayName": "Theovin Lautan",
      "userId": "17106006947934370905"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T02:49:37.986023Z",
     "start_time": "2024-06-17T02:42:41.029860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 72.91it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 134.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0045 , Acc : 0.6952\n",
      "Val_loss: 0.0011, Val_Acc: 0.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 73.24it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 143.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 0.0010 , Acc : 0.9432\n",
      "Val_loss: 0.0007, Val_Acc: 0.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 75.96it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 139.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 0.0007 , Acc : 0.9625\n",
      "Val_loss: 0.0006, Val_Acc: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 74.52it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 143.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 0.0006 , Acc : 0.9674\n",
      "Val_loss: 0.0006, Val_Acc: 0.9662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:10<00:00, 89.35it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 147.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 0.0005 , Acc : 0.9737\n",
      "Val_loss: 0.0005, Val_Acc: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:10<00:00, 89.91it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 148.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 0.0005 , Acc : 0.9747\n",
      "Val_loss: 0.0005, Val_Acc: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 85.42it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 130.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.0004 , Acc : 0.9764\n",
      "Val_loss: 0.0005, Val_Acc: 0.9713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 71.27it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 129.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.0004 , Acc : 0.9794\n",
      "Val_loss: 0.0004, Val_Acc: 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 71.74it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 145.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.0004 , Acc : 0.9796\n",
      "Val_loss: 0.0006, Val_Acc: 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 86.34it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 141.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.0003 , Acc : 0.9835\n",
      "Val_loss: 0.0004, Val_Acc: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 83.93it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 136.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.0003 , Acc : 0.9834\n",
      "Val_loss: 0.0005, Val_Acc: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 81.34it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 145.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.0003 , Acc : 0.9825\n",
      "Val_loss: 0.0004, Val_Acc: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 80.33it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 147.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.0002 , Acc : 0.9868\n",
      "Val_loss: 0.0004, Val_Acc: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:10<00:00, 87.09it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 146.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.0002 , Acc : 0.9870\n",
      "Val_loss: 0.0004, Val_Acc: 0.9767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:10<00:00, 90.42it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 146.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.0002 , Acc : 0.9880\n",
      "Val_loss: 0.0005, Val_Acc: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 83.31it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 127.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.0002 , Acc : 0.9883\n",
      "Val_loss: 0.0005, Val_Acc: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 71.29it/s]\n",
      "100%|██████████| 238/238 [00:02<00:00, 117.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.0002 , Acc : 0.9877\n",
      "Val_loss: 0.0004, Val_Acc: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 70.62it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 143.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.0002 , Acc : 0.9915\n",
      "Val_loss: 0.0004, Val_Acc: 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 78.91it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 136.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.0002 , Acc : 0.9916\n",
      "Val_loss: 0.0005, Val_Acc: 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 83.29it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 133.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.0002 , Acc : 0.9908\n",
      "Val_loss: 0.0004, Val_Acc: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 73.66it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 134.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.0002 , Acc : 0.9907\n",
      "Val_loss: 0.0004, Val_Acc: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 73.55it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 134.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.0001 , Acc : 0.9930\n",
      "Val_loss: 0.0006, Val_Acc: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 74.17it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 139.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.0001 , Acc : 0.9920\n",
      "Val_loss: 0.0005, Val_Acc: 0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 73.19it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 141.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.0001 , Acc : 0.9934\n",
      "Val_loss: 0.0004, Val_Acc: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 73.15it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 141.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.0001 , Acc : 0.9933\n",
      "Val_loss: 0.0004, Val_Acc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 74.12it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 144.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.0001 , Acc : 0.9929\n",
      "Val_loss: 0.0004, Val_Acc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 72.01it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 142.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.0001 , Acc : 0.9927\n",
      "Val_loss: 0.0004, Val_Acc: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:12<00:00, 76.59it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 132.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.0001 , Acc : 0.9931\n",
      "Val_loss: 0.0004, Val_Acc: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:10<00:00, 87.18it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 142.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.0001 , Acc : 0.9948\n",
      "Val_loss: 0.0005, Val_Acc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 86.39it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 141.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.0001 , Acc : 0.9936\n",
      "Val_loss: 0.0005, Val_Acc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "o8fNDn2DlD9d"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
