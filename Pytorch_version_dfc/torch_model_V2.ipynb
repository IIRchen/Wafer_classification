{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"TWjdLoGppE-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715137352422,"user_tz":-480,"elapsed":17610,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}},"outputId":"1200a5db-f2eb-493a-ad7a-76fe69ca3e43"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YJR8bAycY_3Z","executionInfo":{"status":"ok","timestamp":1715137360462,"user_tz":-480,"elapsed":8043,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}}},"outputs":[],"source":["import torch\n","import torchvision.ops\n","from torch import nn\n","\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 dilation=1,\n","                 bias=False):\n","        super(DeformableConv2d, self).__init__()\n","\n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        self.dilation = dilation\n","\n","        self.offset_conv = nn.Conv2d(in_channels,\n","                                     2 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     dilation=self.dilation,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","\n","        self.modulator_conv = nn.Conv2d(in_channels,\n","                                        1 * kernel_size[0] * kernel_size[1],\n","                                        kernel_size=kernel_size,\n","                                        stride=stride,\n","                                        padding=self.padding,\n","                                        dilation=self.dilation,\n","                                        bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      dilation=self.dilation,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        # h, w = x.shape[2:]\n","        # max_offset = max(h, w)/4.\n","\n","        offset = self.offset_conv(x)  # .clamp(-max_offset, max_offset)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        # op = (n - (k * d - 1) + 2p / s)\n","        x = torchvision.ops.deform_conv2d(input=x,\n","                                          offset=offset,\n","                                          weight=self.regular_conv.weight,\n","                                          bias=self.regular_conv.bias,\n","                                          padding=self.padding,\n","                                          mask=modulator,\n","                                          stride=self.stride,\n","                                          dilation=self.dilation)\n","        return x"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Paper_model(nn.Module):\n","    def __init__(self,classes=8, conv_num=32):\n","        super(Paper_model, self).__init__()\n","        bn_axis = 1  # assuming channels first\n","        self.conv_num = conv_num\n","\n","        self.conv_1_offset = DeformableConv2d(1,conv_num)\n","        self.conv_1 = nn.Conv2d(conv_num, conv_num, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_1 = nn.BatchNorm2d(conv_num)\n","\n","        self.conv_2_offset = DeformableConv2d(conv_num,conv_num*2)\n","        self.conv_2 = nn.Conv2d(conv_num * 2 , conv_num * 2, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_2 = nn.BatchNorm2d(conv_num * 2)\n","\n","        self.conv_3_offset = DeformableConv2d(conv_num * 2,conv_num * 4)\n","        self.conv_3 = nn.Conv2d(conv_num * 4, conv_num * 4, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_3 = nn.BatchNorm2d(conv_num * 4)\n","\n","        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(conv_num * 4, classes)\n","\n","    def forward(self, x):\n","        x = self.conv_1_offset(x)\n","        x = self.conv_1(x)\n","        x = self.batch_normalization_1(x)\n","        x = F.relu(x)\n","\n","        x = self.conv_2_offset(x)\n","        x = self.conv_2(x)\n","        x = self.batch_normalization_2(x)\n","        x = F.relu(x)\n","\n","        x = self.conv_3_offset(x)\n","        x = self.conv_3(x)\n","        x = self.batch_normalization_3(x)\n","        x = F.relu(x)\n","\n","\n","\n","        x = self.pooling(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return torch.sigmoid(x)\n"],"metadata":{"id":"QezBSWfrbGfu","executionInfo":{"status":"ok","timestamp":1715137360464,"user_tz":-480,"elapsed":15,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["you = DeformableConv2d(1,50)\n","print(you.forward(torch.randn(1,1,52,52)).shape)\n","x = torch.randn(10,1,52,52)\n","print(type(x))\n","test = Paper_model()\n","print(test.forward(x).shape)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV_uiFEbZXGz","executionInfo":{"status":"ok","timestamp":1715137360881,"user_tz":-480,"elapsed":431,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}},"outputId":"07eda992-f0fe-42c7-a954-4169d20a4751"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 50, 52, 52])\n","<class 'torch.Tensor'>\n","torch.Size([10, 8])\n","Paper_model(\n","  (conv_1_offset): DeformableConv2d(\n","    (offset_conv): Conv2d(1, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(1, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (batch_normalization_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_2_offset): DeformableConv2d(\n","    (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (batch_normalization_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_3_offset): DeformableConv2d(\n","    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (conv_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (batch_normalization_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=128, out_features=8, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","class WaferDataset(Dataset):\n","    def __init__(self, img_array, label_array):\n","        self.img_array = img_array\n","        self.label_array = label_array\n","\n","    def __len__(self):\n","        return len(self.img_array)\n","\n","    def __getitem__(self, idx):\n","        img = torch.from_numpy(self.img_array[idx]).float().unsqueeze(0)  # 转换为 PyTorch 张量\n","        label = torch.from_numpy(self.label_array[idx]).float()  # 转换为 PyTorch 张量\n","        return img, label\n","\n","# 加载数据\n","data = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/V2_dataset.npz')\n","img_array = data['arr_0']\n","label_array = data['arr_1']\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 设置划分比例\n","val_split = 0.2\n","dataset_size = len(wafer_dataset)\n","indices = list(range(dataset_size))\n","np.random.shuffle(indices)\n","val_size = int(np.floor(val_split * dataset_size))\n","train_indices, val_indices = indices[val_size:], indices[:val_size]\n","\n","# 创建训练集和验证集的 SubsetRandomSampler\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","# 创建数据加载器\n","batch_size = 1024\n","train_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=val_sampler)\n"],"metadata":{"id":"NwFDoOGQsyRn","executionInfo":{"status":"ok","timestamp":1715137434568,"user_tz":-480,"elapsed":1345,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 创建数据加载器\n","batch_size = 1024\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","\n","# 使用数据加载器进行训练\n","# 创建模型实例\n","paper_model = Paper_model()\n","\n","# 定义损失函数\n","criterion = nn.BCELoss()\n","\n","# 定义优化器\n","optimizer = optim.Adam(paper_model.parameters(), lr=0.001)  # 可以调整学习率\n","\n","\n","num_epochs = 20\n","# 检查是否有可用的 GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# 将模型移动到设备上\n","paper_model.to(device)\n","\n","# 加载数据集的代码\n","\n","# 创建数据加载器，并将数据移动到设备上\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","dataloader = [(imgs.to(device), labels.to(device)) for imgs, labels in dataloader]\n","\n","import random\n","from tqdm import tqdm\n","def caculate_acc_num(outputs,labels):\n","  acc_num = 0\n","  predicted = (outputs > 0.5).float()\n","  #print(outputs.shape)\n","  for idx in range(predicted.shape[0]):\n","    #print(\"Predicted : \",predicted[idx])\n","    #print(\"Labels : \",labels[idx])\n","    if torch.allclose(predicted[idx], labels[idx]):\n","      acc_num += 1\n","\n","  return acc_num\n","# 使用数据加载器进行训练\n","for epoch in range(num_epochs):\n","    train_acc_num = 0\n","    total_train = 0\n","    train_loss = 0\n","    for imgs, labels in tqdm(train_dataloader):\n","        # 清除梯度\n","        optimizer.zero_grad()\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # 前向传播\n","        outputs = paper_model(imgs)\n","        total_train += imgs.shape[0]\n","        train_acc_num += caculate_acc_num(outputs,labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        train_loss += loss.item()\n","        # 反向传播\n","        loss.backward()\n","\n","        # 更新权重\n","        optimizer.step()\n","        # 随机选择一笔数据打印其标签和预测值\n","        #idx = random.randint(0, len(labels) - 1)\n","        #print(f'Label: {labels[idx]}, Prediction: {(outputs[idx] > 0.5).float()}')\n","\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","    for imgs, labels in tqdm(val_dataloader):\n","        # 前向传播\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = paper_model(imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += caculate_acc_num(outputs, labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","\n","    # 每个 epoch 结束后打印损失\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {(train_loss/total_train):.4f} , Acc : {(train_acc_num/total_train):.4f}')\n","    print(f'Val_loss: {(val_loss/total_val):.4f}, Val_Acc: {(val_acc_num/total_val):.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HDItKcRaga9G","executionInfo":{"status":"error","timestamp":1715137677015,"user_tz":-480,"elapsed":241078,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}},"outputId":"a16d0920-2af8-400f-8c8f-b847e0f82cfa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 0.0005 , Acc : 0.1155\n","Val_loss: 0.0004, Val_Acc: 0.1905\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.68it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Loss: 0.0003 , Acc : 0.3844\n","Val_loss: 0.0003, Val_Acc: 0.5227\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Loss: 0.0002 , Acc : 0.5713\n","Val_loss: 0.0002, Val_Acc: 0.6041\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Loss: 0.0001 , Acc : 0.6651\n","Val_loss: 0.0001, Val_Acc: 0.7725\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Loss: 0.0001 , Acc : 0.8668\n","Val_loss: 0.0001, Val_Acc: 0.9166\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.70it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Loss: 0.0001 , Acc : 0.9260\n","Val_loss: 0.0001, Val_Acc: 0.9362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Loss: 0.0001 , Acc : 0.9392\n","Val_loss: 0.0001, Val_Acc: 0.9388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.68it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Loss: 0.0000 , Acc : 0.9485\n","Val_loss: 0.0000, Val_Acc: 0.9408\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n","100%|██████████| 8/8 [00:02<00:00,  2.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/20], Loss: 0.0000 , Acc : 0.9543\n","Val_loss: 0.0000, Val_Acc: 0.9496\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/20], Loss: 0.0000 , Acc : 0.9616\n","Val_loss: 0.0000, Val_Acc: 0.9553\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n","100%|██████████| 8/8 [00:02<00:00,  2.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/20], Loss: 0.0000 , Acc : 0.9655\n","Val_loss: 0.0000, Val_Acc: 0.9624\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 22/30 [00:13<00:04,  1.63it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-0b39e6d391d6>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# 清除梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# 前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"o8fNDn2DlD9d","executionInfo":{"status":"aborted","timestamp":1715137380354,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}}},"execution_count":null,"outputs":[]}]}