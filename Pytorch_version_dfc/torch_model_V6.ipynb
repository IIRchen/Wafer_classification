{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"TWjdLoGppE-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718610742165,"user_tz":-480,"elapsed":18590,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"outputId":"4ced9aa2-8da6-4c43-a9db-5ab100ebf551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJR8bAycY_3Z"},"outputs":[],"source":["import torch\n","import torchvision.ops\n","from torch import nn\n","\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 dilation=1,\n","                 bias=False):\n","        super(DeformableConv2d, self).__init__()\n","\n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        self.dilation = dilation\n","\n","        self.offset_conv = nn.Conv2d(in_channels,\n","                                     2 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     dilation=self.dilation,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","\n","        self.modulator_conv = nn.Conv2d(in_channels,\n","                                        1 * kernel_size[0] * kernel_size[1],\n","                                        kernel_size=kernel_size,\n","                                        stride=stride,\n","                                        padding=self.padding,\n","                                        dilation=self.dilation,\n","                                        bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      dilation=self.dilation,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        # h, w = x.shape[2:]\n","        # max_offset = max(h, w)/4.\n","\n","        offset = self.offset_conv(x)  # .clamp(-max_offset, max_offset)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        # op = (n - (k * d - 1) + 2p / s)\n","        x = torchvision.ops.deform_conv2d(input=x,\n","                                          offset=offset,\n","                                          weight=self.regular_conv.weight,\n","                                          bias=self.regular_conv.bias,\n","                                          padding=self.padding,\n","                                          mask=modulator,\n","                                          stride=self.stride,\n","                                          dilation=self.dilation)\n","        return x"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Paper_model(nn.Module):\n","    def __init__(self,classes=8, conv_num=32):\n","        super(Paper_model, self).__init__()\n","        bn_axis = 1  # assuming channels first\n","        self.conv_num = conv_num\n","\n","        self.conv_1_offset = DeformableConv2d(1,conv_num)\n","        self.conv_1 = nn.Conv2d(conv_num, conv_num, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_1 = nn.BatchNorm2d(conv_num)\n","\n","        self.conv_2_offset = DeformableConv2d(conv_num,conv_num*2)\n","        self.conv_2 = nn.Conv2d(conv_num * 2 , conv_num * 2, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_2 = nn.BatchNorm2d(conv_num * 2)\n","\n","        self.conv_3_offset = DeformableConv2d(conv_num * 2,conv_num * 4)\n","        self.conv_3 = nn.Conv2d(conv_num * 4, conv_num * 4, kernel_size=3, stride=2, padding=1)\n","        self.batch_normalization_3 = nn.BatchNorm2d(conv_num * 4)\n","\n","        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # self.fc = nn.Linear(conv_num * 4, classes)\n","\n","    def forward(self, x):\n","        x = self.conv_1_offset(x)\n","        x = self.conv_1(x)\n","        x = self.batch_normalization_1(x)\n","        x = F.gelu(x)\n","\n","        x = self.conv_2_offset(x)\n","        x = self.conv_2(x)\n","        x = self.batch_normalization_2(x)\n","        x = F.gelu(x)\n","\n","        x = self.conv_3_offset(x)\n","        x = self.conv_3(x)\n","        x = self.batch_normalization_3(x)\n","        x = F.gelu(x)\n","\n","        x = self.pooling(x)\n","        x = x.view(x.size(0), -1)\n","        # x = self.fc(x)\n","        return x\n"],"metadata":{"id":"QezBSWfrbGfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["you = DeformableConv2d(1,50)\n","print(you.forward(torch.randn(1,1,52,52)).shape)\n","x = torch.randn(10,1,52,52)\n","print(type(x))\n","test = Paper_model()\n","result = test.forward(x)\n","print(result.shape)\n","print(result)\n","\n","x2 = torch.randn(10,1,52,52)\n","result2 = test.forward(x2)\n","out = torch.cat((result, result2), dim=1)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV_uiFEbZXGz","executionInfo":{"status":"ok","timestamp":1718610757929,"user_tz":-480,"elapsed":936,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"outputId":"e52d17a5-18de-4fd6-a273-c0fa160b5f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 50, 52, 52])\n","<class 'torch.Tensor'>\n","torch.Size([10, 128])\n","tensor([[0.4508, 0.2403, 0.3440,  ..., 0.3003, 0.3090, 0.3014],\n","        [0.3023, 0.1288, 0.1969,  ..., 0.2694, 0.2726, 0.1817],\n","        [0.2089, 0.3843, 0.2573,  ..., 0.2168, 0.3658, 0.2738],\n","        ...,\n","        [0.3123, 0.3226, 0.3601,  ..., 0.2394, 0.2039, 0.1937],\n","        [0.2049, 0.1924, 0.1983,  ..., 0.1560, 0.0837, 0.2027],\n","        [0.1538, 0.3451, 0.2888,  ..., 0.3013, 0.2370, 0.1381]],\n","       grad_fn=<ViewBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 256])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["class CombinedModel(nn.Module):\n","    def __init__(self, model1, model2, classes=8, hidden_size=128):\n","        super(CombinedModel, self).__init__()\n","        self.model1 = model1\n","        self.model2 = model2\n","        self.linear = nn.Linear(hidden_size * 2, classes)\n","\n","    def forward(self, x1, x2):\n","        out1 = self.model1(x1)\n","        out2 = self.model2(x2)\n","        combined_output = torch.cat((out1, out2), dim=1)\n","        output = self.linear(combined_output)\n","        return torch.sigmoid(output)"],"metadata":{"id":"lzb3WYRVQvcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = Paper_model()\n","model2 = Paper_model()\n","combined_model = CombinedModel(model1, model2)"],"metadata":{"id":"ADdCYt7GSUF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","class WaferDataset(Dataset):\n","    def __init__(self, img_array_ori, img_array, label_array):\n","        self.img_array_ori = img_array_ori\n","        self.img_array = img_array\n","        self.label_array = label_array\n","\n","\n","    def __len__(self):\n","        return len(self.label_array)\n","\n","    def __getitem__(self, idx):\n","        img_ori = torch.from_numpy(self.img_array_ori[idx]).float().unsqueeze(0)\n","        img = torch.from_numpy(self.img_array[idx]).float().unsqueeze(0)  # 转换为 PyTorch 张量\n","        label = torch.from_numpy(self.label_array[idx]).float()  # 转换为 PyTorch 张量\n","        return img_ori, img, label\n","\n","# 加载数据\n","batch_size = 256\n","data_ori = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/Aug_training_dataset.npz')\n","img_array_ori = data_ori['arr_0']\n","label_array_ori = data_ori['arr_1']\n","data = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/Aug_training_cca_dataaset.npz') # V3_dataset.npz\n","img_array = data['arr_0']\n","label_array = data['arr_1']\n","\n","if len(img_array_ori) != len(img_array):\n","    raise ValueError(\"The lengths of img_array_ori and img_array are not equal\")\n","if len(label_array_ori) != len(label_array):\n","    raise ValueError(\"The lengths of label_array_ori and label_array are not equal\")\n","# 创建数据集\n","train_dataset = WaferDataset(img_array_ori, img_array, label_array)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size\n","                              )\n","val_ori = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/Val_dataset.npz')\n","img_array_ori = val_ori['arr_0']\n","label_array_ori = val_ori['arr_1']\n","\n","val = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/Val_cca_dataaset.npz') # V3_dataset.npz\n","img_array = val['arr_0']\n","label_array = val['arr_1']\n","print(\"Val size \")\n","print(len(label_array))\n","if len(img_array_ori) != len(img_array):\n","    raise ValueError(\"The lengths of img_array_ori and img_array are not equal\")\n","if len(label_array_ori) != len(label_array):\n","    raise ValueError(\"The lengths of label_array_ori and label_array are not equal\")\n","\n","Val_dataset = WaferDataset(img_array_ori, img_array, label_array)\n","# 创建数据加载器\n","\n","val_dataloader = DataLoader(Val_dataset, batch_size=batch_size)\n","\n","print(len(train_dataset))\n","print(len(Val_dataset))\n"],"metadata":{"id":"NwFDoOGQsyRn","executionInfo":{"status":"ok","timestamp":1718610863091,"user_tz":-480,"elapsed":41825,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff08b441-9050-434e-ea90-7a5f49e181d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Val size \n","7603\n","121648\n","7603\n"]}]},{"cell_type":"code","source":["# import torch\n","# from torch.utils.data import TensorDataset, DataLoader\n","# from torch.utils.data.sampler import SubsetRandomSampler\n","#\n","#\n","# dataset = TensorDataset(torch.tensor(list(range(20))))  # 构造一个数据集（0到19）\n","# idx = list(range(len(dataset)))  # 创建索引，SubsetRandomSampler会自动乱序\n","# # idx = torch.zeros(len(dataset)).long()  # 传入相同的索引，SubsetRandomSampler只会采样相同结果\n","# print(idx)\n","# n = len(dataset)\n","# split = n//5\n","# train_sampler = SubsetRandomSampler(idx[split::])  # 随机取80%的数据做训练集\n","# test_sampler = SubsetRandomSampler(idx[::split])  # 随机取20%的数据做测试集\n","# train_loader = DataLoader(dataset, batch_size = 5, sampler=train_sampler)\n","# train_loader_2 = DataLoader(dataset, batch_size = 5, sampler=train_sampler)\n","# test_loader = DataLoader(dataset, batch_size = 5, sampler=test_sampler)\n","#\n","# print('data for training:')\n","# for i in train_loader:\n","#     print(i)\n","# print('data for training2:')\n","# for i in train_loader_2:\n","#     print(i)\n","#\n","# print('data for testing:')\n","# for i in test_loader:\n","#     print(i)"],"metadata":{"id":"b1PDFJMEUMAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","best_acc = 0.9740\n","\n","# 使用数据加载器进行训练\n","# 创建模型实例\n","# paper_model = Paper_model()\n","\n","# 定义损失函数\n","criterion = nn.BCELoss()\n","\n","# 定义优化器\n","optimizer = optim.Adam(combined_model.parameters(), lr=0.001)  # 可以调整学习率\n","\n","\n","num_epochs = 30\n","# 检查是否有可用的 GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# 将模型移动到设备上\n","combined_model.to(device)\n","\n","\n","import random\n","from tqdm import tqdm\n","def caculate_acc_num(outputs,labels):\n","  acc_num = 0\n","  predicted = (outputs > 0.5).float()\n","  #print(outputs.shape)\n","  for idx in range(predicted.shape[0]):\n","    #print(\"Predicted : \",predicted[idx])\n","    #print(\"Labels : \",labels[idx])\n","    if torch.allclose(predicted[idx], labels[idx]):\n","      acc_num += 1\n","\n","  return acc_num\n","# 使用数据加载器进行训练\n","for epoch in range(num_epochs):\n","    train_acc_num = 0\n","    total_train = 0\n","    train_loss = 0\n","    for imgs_ori, imgs, labels in tqdm(train_dataloader):\n","        # 清除梯度\n","        optimizer.zero_grad()\n","        imgs_ori = imgs_ori.to(device)\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # 前向传播\n","        outputs = combined_model(imgs_ori, imgs)\n","        total_train += imgs.shape[0]\n","        train_acc_num += caculate_acc_num(outputs,labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        train_loss += loss.item()\n","        # 反向传播\n","        loss.backward()\n","\n","        # 更新权重\n","        optimizer.step()\n","        # 随机选择一笔数据打印其标签和预测值\n","        #idx = random.randint(0, len(labels) - 1)\n","        #print(f'Label: {labels[idx]}, Prediction: {(outputs[idx] > 0.5).float()}')\n","\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","    for imgs_ori, imgs, labels in tqdm(val_dataloader):\n","        # 前向传播\n","        imgs_ori = imgs_ori.to(device)\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = combined_model(imgs_ori, imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += caculate_acc_num(outputs, labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","\n","    # 每个 epoch 结束后打印损失\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {(train_loss/total_train):.4f} , Acc : {(train_acc_num/total_train):.4f}')\n","    print(f'Val_loss: {(val_loss/total_val):.4f}, Val_Acc: {(val_acc_num/total_val):.4f}')\n","\n","    if (val_acc_num/total_val) > best_acc :\n","      best_acc = (val_acc_num/total_val)\n","      torch.save(combined_model.state_dict(), f'/content/drive/MyDrive/DeepLearning_project/Pytorch_version_dfc/V6_weight/weight_{best_acc:.4f}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDItKcRaga9G","outputId":"023e8656-cd2d-4fa8-8f1b-e076355151b7","executionInfo":{"status":"ok","timestamp":1718529354625,"user_tz":-480,"elapsed":3784510,"user":{"displayName":"陳冠宇","userId":"02437951698618350437"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.85it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.0000 , Acc : 0.9771\n","Val_loss: 0.0001, Val_Acc: 0.9749\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/30], Loss: 0.0000 , Acc : 0.9787\n","Val_loss: 0.0000, Val_Acc: 0.9765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.84it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/30], Loss: 0.0000 , Acc : 0.9822\n","Val_loss: 0.0001, Val_Acc: 0.9769\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.86it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/30], Loss: 0.0000 , Acc : 0.9826\n","Val_loss: 0.0000, Val_Acc: 0.9780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/30], Loss: 0.0000 , Acc : 0.9850\n","Val_loss: 0.0000, Val_Acc: 0.9780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/30], Loss: 0.0000 , Acc : 0.9849\n","Val_loss: 0.0000, Val_Acc: 0.9778\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/30], Loss: 0.0000 , Acc : 0.9865\n","Val_loss: 0.0000, Val_Acc: 0.9805\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/30], Loss: 0.0000 , Acc : 0.9866\n","Val_loss: 0.0001, Val_Acc: 0.9790\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/30], Loss: 0.0000 , Acc : 0.9882\n","Val_loss: 0.0001, Val_Acc: 0.9779\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.86it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/30], Loss: 0.0000 , Acc : 0.9882\n","Val_loss: 0.0001, Val_Acc: 0.9787\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/30], Loss: 0.0000 , Acc : 0.9893\n","Val_loss: 0.0001, Val_Acc: 0.9783\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/30], Loss: 0.0000 , Acc : 0.9898\n","Val_loss: 0.0001, Val_Acc: 0.9787\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/30], Loss: 0.0000 , Acc : 0.9900\n","Val_loss: 0.0001, Val_Acc: 0.9788\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/30], Loss: 0.0000 , Acc : 0.9914\n","Val_loss: 0.0001, Val_Acc: 0.9778\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/30], Loss: 0.0000 , Acc : 0.9912\n","Val_loss: 0.0001, Val_Acc: 0.9767\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/30], Loss: 0.0000 , Acc : 0.9919\n","Val_loss: 0.0001, Val_Acc: 0.9801\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.86it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/30], Loss: 0.0000 , Acc : 0.9920\n","Val_loss: 0.0001, Val_Acc: 0.9795\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/30], Loss: 0.0000 , Acc : 0.9920\n","Val_loss: 0.0001, Val_Acc: 0.9776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/30], Loss: 0.0000 , Acc : 0.9932\n","Val_loss: 0.0001, Val_Acc: 0.9782\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/30], Loss: 0.0000 , Acc : 0.9922\n","Val_loss: 0.0001, Val_Acc: 0.9794\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [21/30], Loss: 0.0000 , Acc : 0.9924\n","Val_loss: 0.0001, Val_Acc: 0.9804\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.86it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [22/30], Loss: 0.0000 , Acc : 0.9941\n","Val_loss: 0.0000, Val_Acc: 0.9817\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:02<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [23/30], Loss: 0.0000 , Acc : 0.9936\n","Val_loss: 0.0001, Val_Acc: 0.9792\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.86it/s]\n","100%|██████████| 30/30 [00:02<00:00, 11.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [24/30], Loss: 0.0000 , Acc : 0.9933\n","Val_loss: 0.0001, Val_Acc: 0.9791\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [25/30], Loss: 0.0000 , Acc : 0.9941\n","Val_loss: 0.0001, Val_Acc: 0.9796\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.87it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [26/30], Loss: 0.0000 , Acc : 0.9940\n","Val_loss: 0.0001, Val_Acc: 0.9784\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.85it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [27/30], Loss: 0.0000 , Acc : 0.9941\n","Val_loss: 0.0001, Val_Acc: 0.9807\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.84it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [28/30], Loss: 0.0000 , Acc : 0.9942\n","Val_loss: 0.0001, Val_Acc: 0.9787\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.84it/s]\n","100%|██████████| 30/30 [00:02<00:00, 10.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [29/30], Loss: 0.0000 , Acc : 0.9956\n","Val_loss: 0.0001, Val_Acc: 0.9791\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 476/476 [02:03<00:00,  3.85it/s]\n","100%|██████████| 30/30 [00:03<00:00,  9.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [30/30], Loss: 0.0000 , Acc : 0.9949\n","Val_loss: 0.0001, Val_Acc: 0.9792\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["combined_model = CombinedModel(model1, model2)  # create an instance of the model\n","combined_model.load_state_dict(torch.load(f'/content/drive/MyDrive/DeepLearning_project/Pytorch_version_dfc/V6_weight/weight_0.9817.pth'))\n","combined_model.eval()"],"metadata":{"id":"rbmV-9eWc2ZU","executionInfo":{"status":"ok","timestamp":1718610864285,"user_tz":-480,"elapsed":1197,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f87fbe5-65ee-4938-83c8-b82193df5992"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CombinedModel(\n","  (model1): Paper_model(\n","    (conv_1_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(1, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(1, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv_2_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv_3_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (model2): Paper_model(\n","    (conv_1_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(1, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(1, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv_2_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv_3_offset): DeformableConv2d(\n","      (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (conv_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batch_normalization_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (linear): Linear(in_features=256, out_features=8, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["!pip install thop\n","from thop import profile  # Import the profiler\n","import torch.optim as optim\n","from tqdm import tqdm\n","\n","# Define the loss function\n","criterion = nn.BCELoss()\n","# Define the optimizer\n","optimizer = optim.Adam(combined_model.parameters(), lr=0.001)  # Adjustable learning rate\n","\n","def calculate_acc_num(outputs, labels):\n","    acc_num = 0\n","    predicted = (outputs > 0.5).float()\n","    for idx in range(predicted.shape[0]):\n","        if torch.allclose(predicted[idx], labels[idx]):\n","            acc_num += 1\n","    return acc_num\n","\n","def evaluate_model(model, dataloader, device):\n","    model.to(device)\n","    model.eval()\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","    # Assume the first batch to infer the input size for FLOPs calculation\n","    first_batch = next(iter(dataloader))\n","    imgs_ori, imgs, _ = first_batch\n","    input_shape = imgs_ori.shape  # Assuming imgs_ori to be representative\n","\n","    # Calculate FLOPs and Parameters\n","    flops, params = profile(model, inputs=(imgs_ori.to(device), imgs.to(device)), verbose=False)\n","\n","    # Convert FLOPs to GigaFLOPs and parameters to thousands (K)\n","    flops_in_gflops = flops / 1e9  # Convert from FLOPs to GFLOPs\n","    params_in_k = params / 1e3     # Convert from parameters to thousands\n","\n","    # Print the results formatted as GFLOPs and K\n","    print(f\"FLOPs: {flops_in_gflops:.4f} GFLOPs   Params: {params_in_k:.3f}K\")\n","\n","    for imgs_ori, imgs, labels in tqdm(dataloader):\n","        imgs_ori = imgs_ori.to(device)\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = model(imgs_ori, imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += calculate_acc_num(outputs, labels)\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","    print(f'Val_loss: {val_loss / total_val:.4f}, Val_Acc: {val_acc_num / total_val:.4f}')\n","    return outputs\n","\n","outputs = evaluate_model(combined_model, val_dataloader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8tD5rge4hB1","executionInfo":{"status":"ok","timestamp":1718610944052,"user_tz":-480,"elapsed":79771,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"outputId":"5eee480e-bf38-46cf-d5ac-d63816912c2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->thop)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->thop)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->thop)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->thop)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->thop)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->thop)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->thop)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->thop)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238\n","FLOPs: 14.5355 GFLOPs   Params: 437.776K\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:02<00:00, 10.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Val_loss: 0.0001, Val_Acc: 0.9816\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["CLASS_MAPPING = {\n","    \"[0 0 0 0 0 0 0 0]\":0,\n","    \"[1 0 0 0 0 0 0 0]\":1,\n","    \"[0 1 0 0 0 0 0 0]\":2,\n","    \"[0 0 1 0 0 0 0 0]\":3,\n","    \"[0 0 0 1 0 0 0 0]\":4,\n","    \"[0 0 0 0 1 0 0 0]\":5,\n","    \"[0 0 0 0 0 1 0 0]\":6,\n","    \"[0 0 0 0 0 0 1 0]\":7,\n","    \"[0 0 0 0 0 0 0 1]\":8,\n","    \"[1 0 1 0 0 0 0 0]\":9,\n","    \"[1 0 0 1 0 0 0 0]\":10,\n","    \"[1 0 0 0 1 0 0 0]\":11,\n","    \"[1 0 0 0 0 0 1 0]\":12,\n","    \"[0 1 1 0 0 0 0 0]\":13,\n","    \"[0 1 0 1 0 0 0 0]\":14,\n","    \"[0 1 0 0 1 0 0 0]\":15,\n","    \"[0 1 0 0 0 0 1 0]\":16,\n","    \"[0 0 1 0 1 0 0 0]\":17,\n","    \"[0 0 1 0 0 0 1 0]\":18,\n","    \"[0 0 0 1 1 0 0 0]\":19,\n","    \"[0 0 0 1 0 0 1 0]\":20,\n","    \"[0 0 0 0 1 0 1 0]\":21,\n","    \"[1 0 1 0 1 0 0 0]\":22,\n","    \"[1 0 1 0 0 0 1 0]\":23,\n","    \"[1 0 0 1 1 0 0 0]\":24,\n","    \"[1 0 0 1 0 0 1 0]\":25,\n","    \"[1 0 0 0 1 0 1 0]\":26,\n","    \"[0 1 1 0 1 0 0 0]\":27,\n","    \"[0 1 1 0 0 0 1 0]\":28,\n","    \"[0 1 0 1 1 0 0 0]\":29,\n","    \"[0 1 0 1 0 0 1 0]\":30,\n","    \"[0 1 0 0 1 0 1 0]\":31,\n","    \"[0 0 1 0 1 0 1 0]\":32,\n","    \"[0 0 0 1 1 0 1 0]\":33,\n","    \"[1 0 1 0 1 0 1 0]\":34,\n","    \"[1 0 0 1 1 0 1 0]\":35,\n","    \"[0 1 1 0 1 0 1 0]\":36,\n","    \"[0 1 0 1 1 0 1 0]\":37\n","}\n","\n","#%%\n","key = \"[0 1 0 1 1 0 1 0]\"\n","value = CLASS_MAPPING[\"[0 1 0 1 1 0 1 0]\"]\n","print(value)\n","#%%\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def plot_confusion_matrix_and_accuracy(model, dataloader, device, class_mapping):\n","    num_classes = len(class_mapping)\n","    class_labels = [None] * num_classes\n","    for label_str, index in class_mapping.items():\n","        class_labels[index] = str(index)  # Directly use the numerical identifier\n","\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for imgs_ori, imgs, labels in tqdm(dataloader):\n","            imgs_ori = imgs_ori.to(device)\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(imgs_ori, imgs)\n","            predicted = (outputs > 0.5).float()\n","\n","            for i in range(labels.size(0)):\n","                label_vec = labels[i].to(torch.uint8).tolist()\n","                label_str = '[' + ' '.join(map(str, label_vec)) + ']'\n","                class_idx = class_mapping[label_str]\n","\n","                pred_vec = predicted[i].tolist()\n","                pred_str = '[' + ' '.join(str(int(p)) for p in pred_vec) + ']'\n","                pred_idx = class_mapping.get(pred_str, -1)  # Handle unseen/misformatted predictions\n","\n","                all_labels.append(class_idx)\n","                all_predictions.append(pred_idx)\n","\n","    # Compute the confusion matrix\n","    conf_mat = confusion_matrix(all_labels, all_predictions, labels=range(len(class_mapping)))\n","\n","    # # Plotting the confusion matrix\n","    # plt.figure(figsize=(15, 13))  # Increase figure size\n","    # ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","    # plt.title('Confusion Matrix', size=20)  # Increase title font size\n","    # plt.ylabel('True Label', size=18)  # Increase y-axis label font size\n","    # plt.xlabel('Predicted Label', size=18)  # Increase x-axis label font size\n","\n","    # # Improve layout to prevent cut-off issues\n","    # plt.xticks(rotation=90, size=10)  # Rotate x labels for better fit, adjust size as needed\n","    # plt.yticks(size=10)  # Adjust y labels size as needed\n","    # plt.tight_layout()  # This adjusts subplot params so that the subplot(s) fits in to the figure area\n","\n","    # plt.show()\n","\n","    # Printing classification report\n","    print(classification_report(\n","        all_labels,\n","        all_predictions,\n","        target_names=class_labels,\n","        labels=range(len(class_labels))  # Ensure it considers all classes\n","    ))\n","\n","    # Calculate and print class-specific accuracy\n","    class_accuracy = 100 * conf_mat.diagonal() / conf_mat.sum(axis=1)\n","    for i, accuracy in enumerate(class_accuracy):\n","        if not np.isnan(accuracy):\n","            print(f'Accuracy of class {class_labels[i]} : {accuracy:.2f}%')\n","        else:\n","            print(f'No samples for class {class_labels[i]}')\n","\n","# Call the function\n","plot_confusion_matrix_and_accuracy(combined_model, val_dataloader, device, CLASS_MAPPING)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuGIpyOuHsbl","executionInfo":{"status":"ok","timestamp":1718611306481,"user_tz":-480,"elapsed":2613,"user":{"displayName":"RE6125015劉仁忠","userId":"02371008579624911904"}},"outputId":"a61e446e-762f-425f-ff81-5ca22c577098"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["37\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:02<00:00, 14.23it/s]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       200\n","           1       0.99      1.00      1.00       200\n","           2       0.97      1.00      0.99       200\n","           3       0.99      0.99      0.99       200\n","           4       0.98      0.98      0.98       200\n","           5       0.98      0.99      0.99       200\n","           6       1.00      1.00      1.00        30\n","           7       0.99      0.99      0.99       200\n","           8       1.00      0.99      1.00       173\n","           9       0.98      0.98      0.98       200\n","          10       0.99      0.99      0.99       200\n","          11       0.97      0.99      0.98       200\n","          12       0.98      0.99      0.98       200\n","          13       0.98      0.99      0.99       200\n","          14       0.97      0.97      0.97       200\n","          15       0.98      0.99      0.98       200\n","          16       0.98      0.98      0.98       200\n","          17       0.97      0.98      0.98       200\n","          18       1.00      0.99      1.00       200\n","          19       0.98      0.98      0.98       200\n","          20       0.99      1.00      0.99       200\n","          21       0.98      0.97      0.97       200\n","          22       0.96      0.95      0.95       200\n","          23       0.99      0.99      0.99       400\n","          24       0.97      0.96      0.97       200\n","          25       0.98      0.99      0.99       200\n","          26       0.99      0.96      0.97       200\n","          27       0.99      0.99      0.99       200\n","          28       0.96      0.94      0.95       200\n","          29       0.98      0.97      0.98       200\n","          30       0.96      0.98      0.97       200\n","          31       0.98      0.97      0.97       200\n","          32       0.99      0.95      0.97       200\n","          33       0.99      0.97      0.98       200\n","          34       0.98      0.96      0.97       200\n","          35       0.98      0.98      0.98       200\n","          36       1.00      0.94      0.97       200\n","          37       0.99      0.99      0.99       200\n","\n","   micro avg       0.98      0.98      0.98      7603\n","   macro avg       0.98      0.98      0.98      7603\n","weighted avg       0.98      0.98      0.98      7603\n","\n","Accuracy of class 0 : 100.00%\n","Accuracy of class 1 : 100.00%\n","Accuracy of class 2 : 100.00%\n","Accuracy of class 3 : 99.50%\n","Accuracy of class 4 : 98.50%\n","Accuracy of class 5 : 99.00%\n","Accuracy of class 6 : 100.00%\n","Accuracy of class 7 : 99.50%\n","Accuracy of class 8 : 99.42%\n","Accuracy of class 9 : 98.50%\n","Accuracy of class 10 : 99.50%\n","Accuracy of class 11 : 99.00%\n","Accuracy of class 12 : 99.00%\n","Accuracy of class 13 : 99.50%\n","Accuracy of class 14 : 97.50%\n","Accuracy of class 15 : 99.00%\n","Accuracy of class 16 : 98.00%\n","Accuracy of class 17 : 98.50%\n","Accuracy of class 18 : 99.50%\n","Accuracy of class 19 : 98.00%\n","Accuracy of class 20 : 100.00%\n","Accuracy of class 21 : 97.00%\n","Accuracy of class 22 : 95.00%\n","Accuracy of class 23 : 99.00%\n","Accuracy of class 24 : 96.98%\n","Accuracy of class 25 : 99.50%\n","Accuracy of class 26 : 96.00%\n","Accuracy of class 27 : 99.00%\n","Accuracy of class 28 : 94.50%\n","Accuracy of class 29 : 97.50%\n","Accuracy of class 30 : 98.00%\n","Accuracy of class 31 : 97.00%\n","Accuracy of class 32 : 95.50%\n","Accuracy of class 33 : 97.00%\n","Accuracy of class 34 : 96.00%\n","Accuracy of class 35 : 98.00%\n","Accuracy of class 36 : 94.50%\n","Accuracy of class 37 : 99.00%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}