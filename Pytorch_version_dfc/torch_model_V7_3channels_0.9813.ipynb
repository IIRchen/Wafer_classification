{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eHtXd1vTliT","executionInfo":{"status":"ok","timestamp":1718634632863,"user_tz":-480,"elapsed":2543,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"outputId":"2e4d86fa-633c-4ba6-d2ed-38a215b99039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"metadata":{"ExecuteTime":{"end_time":"2024-06-17T02:20:17.644266Z","start_time":"2024-06-17T02:20:17.635023Z"},"id":"s0vdxFAqSwzF"},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.ops\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 dilation=1,\n","                 bias=False):\n","        super(DeformableConv2d, self).__init__()\n","\n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        self.dilation = dilation\n","\n","        self.offset_conv = nn.Conv2d(in_channels,\n","                                     2 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     dilation=self.dilation,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","\n","        self.modulator_conv = nn.Conv2d(in_channels,\n","                                        1 * kernel_size[0] * kernel_size[1],\n","                                        kernel_size=kernel_size,\n","                                        stride=stride,\n","                                        padding=self.padding,\n","                                        dilation=self.dilation,\n","                                        bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      dilation=self.dilation,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        offset = self.offset_conv(x)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        x = torchvision.ops.deform_conv2d(input=x,\n","                                          offset=offset,\n","                                          weight=self.regular_conv.weight,\n","                                          bias=self.regular_conv.bias,\n","                                          padding=self.padding,\n","                                          mask=modulator,\n","                                          stride=self.stride,\n","                                          dilation=self.dilation)\n","        return x\n","\n","class Attention(nn.Module):\n","    def __init__(self, in_channels):\n","        super(Attention, self).__init__()\n","        self.attention = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        attention = self.attention(x)\n","        return x * attention\n","\n","\n","class CBAM(nn.Module):\n","    def __init__(self, channels, r):\n","        super(CBAM, self).__init__()\n","        self.channels = channels\n","        self.r = r\n","        self.sam = SAM(bias=False)\n","        self.cam = CAM(channels=self.channels, r=self.r)\n","\n","    def forward(self, x):\n","        output = self.cam(x)\n","        output = self.sam(output)\n","        return output + x\n","\n","\n","class CAM(nn.Module):\n","    def __init__(self, channels, r):\n","        super(CAM, self).__init__()\n","        self.channels = channels\n","        self.r = r\n","        self.linear = nn.Sequential(\n","            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n","\n","    def forward(self, x):\n","        max = F.adaptive_max_pool2d(x, output_size=1)\n","        avg = F.adaptive_avg_pool2d(x, output_size=1)\n","        b, c, _, _ = x.size()\n","        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n","        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n","        output = linear_max + linear_avg\n","        output = F.sigmoid(output) * x\n","        return output\n","\n","class SAM(nn.Module):\n","    def __init__(self, bias=False):\n","        super(SAM, self).__init__()\n","        self.bias = bias\n","        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n","\n","    def forward(self, x):\n","        max = torch.max(x,1)[0].unsqueeze(1)\n","        avg = torch.mean(x,1).unsqueeze(1)\n","        concat = torch.cat((max,avg), dim=1)\n","        output = self.conv(concat)\n","        output = F.sigmoid(output) * x\n","        return output"],"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Paper_model(nn.Module):\n","    def __init__(self):\n","        super(Paper_model, self).__init__()\n","        self.layer1 = DeformableConv2d(3, 32, bias=True)\n","        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.attention1 = CBAM(32, r=2)\n","        self.bn1 = nn.LayerNorm([32, 52, 52])\n","        self.pool1 = nn.MaxPool2d(2)\n","\n","        self.layer3 = DeformableConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.attention2 = CBAM(64, r=2)\n","        self.pool2 = nn.MaxPool2d(2)\n","        self.bn2 = nn.LayerNorm([64, 26, 26])\n","\n","        self.layer5 = DeformableConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.attention3 = CBAM(128, r=2)\n","        self.pool3 = nn.MaxPool2d(2)\n","        self.bn3 = nn.LayerNorm([128, 13, 13])\n","\n","        self.dropout = nn.Dropout(0.5)\n","        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc1 = nn.Linear(128, 8)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.bn1(x)\n","        x = F.gelu(x)\n","        x = self.attention1(x)\n","        x = self.pool1(x)\n","\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.bn2(x)\n","        x = F.gelu(x)\n","        x = self.attention2(x)\n","        x = self.pool2(x)\n","\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.bn3(x)\n","        x = F.gelu(x)\n","        x = self.attention3(x)\n","        x = self.pool3(x)\n","\n","        x = self.pooling(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc1(x)\n","        return torch.sigmoid(x)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","dcn_model = Paper_model().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(dcn_model.parameters(), lr=0.001)\n","print(dcn_model)"],"metadata":{"id":"QezBSWfrbGfu","executionInfo":{"status":"ok","timestamp":1718632757778,"user_tz":-480,"elapsed":551,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"ExecuteTime":{"end_time":"2024-06-17T02:42:36.419769Z","start_time":"2024-06-17T02:42:36.403276Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d4c0b77-e548-48d8-ec72-6334c49febbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Paper_model(\n","  (layer1): DeformableConv2d(\n","    (offset_conv): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention1): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=32, out_features=16, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=16, out_features=32, bias=True)\n","      )\n","    )\n","  )\n","  (bn1): LayerNorm((32, 52, 52), eps=1e-05, elementwise_affine=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (layer3): DeformableConv2d(\n","    (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention2): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=64, out_features=32, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=32, out_features=64, bias=True)\n","      )\n","    )\n","  )\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (bn2): LayerNorm((64, 26, 26), eps=1e-05, elementwise_affine=True)\n","  (layer5): DeformableConv2d(\n","    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention3): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=128, out_features=64, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=64, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (bn3): LayerNorm((128, 13, 13), eps=1e-05, elementwise_affine=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc1): Linear(in_features=128, out_features=8, bias=True)\n",")\n"]}],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","class WaferDataset(Dataset):\n","    def __init__(self, img_array, label_array):\n","        self.img_array = img_array\n","        self.label_array = label_array\n","\n","    def __len__(self):\n","        return len(self.img_array)\n","\n","    def __getitem__(self, idx):\n","        img = torch.from_numpy(self.img_array[idx]).float()\n","        if img.ndim == 2:  # If the image is grayscale\n","            img = img.unsqueeze(0).repeat(3, 1, 1)  # Repeat the single channel 3 times\n","        elif img.ndim == 3:  # If the image is already multi-channel but in [H, W, C] format\n","            img = img.permute(2, 0, 1)  # Rearrange from [H, W, C] to [C, H, W]\n","        label = torch.from_numpy(self.label_array[idx]).float()\n","        return img, label\n","\n","# 加载数据\n","data = np.load('/content/drive/MyDrive/DeepLearning_project/Dataset/images_3chnl.npz') # V3_dataset.npz\n","img_array = data['arr_0']\n","label_array = data['arr_1']\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 设置划分比例\n","val_split = 0.2\n","dataset_size = len(wafer_dataset)\n","indices = list(range(dataset_size))\n","np.random.shuffle(indices)\n","val_size = int(np.floor(val_split * dataset_size))\n","train_indices, val_indices = indices[val_size:], indices[:val_size]\n","\n","# 创建训练集和验证集的 SubsetRandomSampler\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","# 创建数据加载器\n","batch_size = 32\n","train_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=val_sampler)\n"],"metadata":{"id":"NwFDoOGQsyRn","ExecuteTime":{"end_time":"2024-06-17T02:41:47.097184Z","start_time":"2024-06-17T02:41:46.498893Z"}},"outputs":[],"execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2024-06-17T02:26:30.123076Z","start_time":"2024-06-17T02:26:30.119808Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"u5Xq2ybiSwzJ","executionInfo":{"status":"ok","timestamp":1718632938562,"user_tz":-480,"elapsed":4,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"outputId":"d6c9e2d0-3815-4b09-f883-d53218f9011a"},"cell_type":"code","source":["img_array.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(38015, 52, 52, 3)"]},"metadata":{},"execution_count":10}],"execution_count":null},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","best_acc = 0.9740\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 创建数据加载器\n","batch_size = 32\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","\n","# 使用数据加载器进行训练\n","# 创建模型实例\n","paper_model = Paper_model()\n","\n","# 定义损失函数\n","criterion = nn.BCELoss()\n","\n","# 定义优化器\n","optimizer = optim.Adam(paper_model.parameters(), lr=0.001)  # 可以调整学习率\n","\n","\n","num_epochs = 30\n","# 检查是否有可用的 GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# 将模型移动到设备上\n","paper_model.to(device)\n","\n","# 加载数据集的代码\n","\n","# 创建数据加载器，并将数据移动到设备上\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","dataloader = [(imgs.to(device), labels.to(device)) for imgs, labels in dataloader]\n","\n","import random\n","from tqdm import tqdm\n","def caculate_acc_num(outputs,labels):\n","  acc_num = 0\n","  predicted = (outputs > 0.5).float()\n","  #print(outputs.shape)\n","  for idx in range(predicted.shape[0]):\n","    #print(\"Predicted : \",predicted[idx])\n","    #print(\"Labels : \",labels[idx])\n","    if torch.allclose(predicted[idx], labels[idx]):\n","      acc_num += 1\n","\n","  return acc_num\n","# 使用数据加载器进行训练\n","for epoch in range(num_epochs):\n","    train_acc_num = 0\n","    total_train = 0\n","    train_loss = 0\n","    for imgs, labels in tqdm(train_dataloader):\n","        # 清除梯度\n","        optimizer.zero_grad()\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # 前向传播\n","        outputs = paper_model(imgs)\n","        total_train += imgs.shape[0]\n","        train_acc_num += caculate_acc_num(outputs,labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        train_loss += loss.item()\n","        # 反向传播\n","        loss.backward()\n","\n","        # 更新权重\n","        optimizer.step()\n","        # 随机选择一笔数据打印其标签和预测值\n","        #idx = random.randint(0, len(labels) - 1)\n","        #print(f'Label: {labels[idx]}, Prediction: {(outputs[idx] > 0.5).float()}')\n","\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","    for imgs, labels in tqdm(val_dataloader):\n","        # 前向传播\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = paper_model(imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += caculate_acc_num(outputs, labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","\n","    # 每个 epoch 结束后打印损失\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {(train_loss/total_train):.4f} , Acc : {(train_acc_num/total_train):.4f}')\n","    print(f'Val_loss: {(val_loss/total_val):.4f}, Val_Acc: {(val_acc_num/total_val):.4f}')\n","\n","    if (val_acc_num/total_val) > best_acc :\n","      best_acc = (val_acc_num/total_val)\n","      torch.save(paper_model.state_dict(), f'/content/drive/MyDrive/DeepLearning_project/Pytorch_version_dfc/V7_weight/weight_{best_acc:.4f}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDItKcRaga9G","outputId":"4d7346db-2e03-4ca0-f6ff-5bbffc91d6f9","executionInfo":{"status":"ok","timestamp":1718633892483,"user_tz":-480,"elapsed":953924,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"ExecuteTime":{"end_time":"2024-06-17T02:49:37.986023Z","start_time":"2024-06-17T02:42:41.029860Z"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:31<00:00, 30.23it/s]\n","100%|██████████| 238/238 [00:03<00:00, 66.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.0050 , Acc : 0.6393\n","Val_loss: 0.0016, Val_Acc: 0.8891\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.39it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/30], Loss: 0.0011 , Acc : 0.9370\n","Val_loss: 0.0009, Val_Acc: 0.9498\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.37it/s]\n","100%|██████████| 238/238 [00:03<00:00, 69.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/30], Loss: 0.0007 , Acc : 0.9569\n","Val_loss: 0.0007, Val_Acc: 0.9561\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.68it/s]\n","100%|██████████| 238/238 [00:03<00:00, 73.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/30], Loss: 0.0006 , Acc : 0.9646\n","Val_loss: 0.0006, Val_Acc: 0.9638\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.60it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/30], Loss: 0.0005 , Acc : 0.9702\n","Val_loss: 0.0006, Val_Acc: 0.9697\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.80it/s]\n","100%|██████████| 238/238 [00:03<00:00, 66.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/30], Loss: 0.0005 , Acc : 0.9745\n","Val_loss: 0.0006, Val_Acc: 0.9687\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.63it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/30], Loss: 0.0004 , Acc : 0.9777\n","Val_loss: 0.0005, Val_Acc: 0.9704\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.86it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/30], Loss: 0.0004 , Acc : 0.9787\n","Val_loss: 0.0004, Val_Acc: 0.9762\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.75it/s]\n","100%|██████████| 238/238 [00:03<00:00, 61.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/30], Loss: 0.0004 , Acc : 0.9795\n","Val_loss: 0.0004, Val_Acc: 0.9774\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.92it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/30], Loss: 0.0003 , Acc : 0.9828\n","Val_loss: 0.0005, Val_Acc: 0.9754\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.87it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/30], Loss: 0.0003 , Acc : 0.9829\n","Val_loss: 0.0007, Val_Acc: 0.9650\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.80it/s]\n","100%|██████████| 238/238 [00:03<00:00, 63.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/30], Loss: 0.0003 , Acc : 0.9860\n","Val_loss: 0.0006, Val_Acc: 0.9666\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.87it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/30], Loss: 0.0002 , Acc : 0.9865\n","Val_loss: 0.0007, Val_Acc: 0.9595\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.93it/s]\n","100%|██████████| 238/238 [00:03<00:00, 74.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/30], Loss: 0.0003 , Acc : 0.9856\n","Val_loss: 0.0004, Val_Acc: 0.9737\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.51it/s]\n","100%|██████████| 238/238 [00:03<00:00, 67.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/30], Loss: 0.0002 , Acc : 0.9882\n","Val_loss: 0.0004, Val_Acc: 0.9816\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.78it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/30], Loss: 0.0002 , Acc : 0.9883\n","Val_loss: 0.0004, Val_Acc: 0.9763\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.80it/s]\n","100%|██████████| 238/238 [00:03<00:00, 70.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/30], Loss: 0.0002 , Acc : 0.9866\n","Val_loss: 0.0004, Val_Acc: 0.9783\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.49it/s]\n","100%|██████████| 238/238 [00:03<00:00, 73.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/30], Loss: 0.0002 , Acc : 0.9909\n","Val_loss: 0.0004, Val_Acc: 0.9741\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.90it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/30], Loss: 0.0002 , Acc : 0.9919\n","Val_loss: 0.0004, Val_Acc: 0.9770\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.85it/s]\n","100%|██████████| 238/238 [00:03<00:00, 67.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/30], Loss: 0.0002 , Acc : 0.9909\n","Val_loss: 0.0006, Val_Acc: 0.9721\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.53it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [21/30], Loss: 0.0002 , Acc : 0.9897\n","Val_loss: 0.0005, Val_Acc: 0.9763\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.80it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [22/30], Loss: 0.0001 , Acc : 0.9931\n","Val_loss: 0.0006, Val_Acc: 0.9726\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.87it/s]\n","100%|██████████| 238/238 [00:03<00:00, 63.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [23/30], Loss: 0.0002 , Acc : 0.9902\n","Val_loss: 0.0004, Val_Acc: 0.9779\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.70it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [24/30], Loss: 0.0001 , Acc : 0.9939\n","Val_loss: 0.0004, Val_Acc: 0.9803\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.92it/s]\n","100%|██████████| 238/238 [00:03<00:00, 75.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [25/30], Loss: 0.0002 , Acc : 0.9902\n","Val_loss: 0.0005, Val_Acc: 0.9755\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.90it/s]\n","100%|██████████| 238/238 [00:03<00:00, 62.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [26/30], Loss: 0.0001 , Acc : 0.9931\n","Val_loss: 0.0005, Val_Acc: 0.9733\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.74it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [27/30], Loss: 0.0001 , Acc : 0.9944\n","Val_loss: 0.0004, Val_Acc: 0.9797\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.34it/s]\n","100%|██████████| 238/238 [00:03<00:00, 74.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [28/30], Loss: 0.0001 , Acc : 0.9940\n","Val_loss: 0.0006, Val_Acc: 0.9722\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 32.96it/s]\n","100%|██████████| 238/238 [00:03<00:00, 63.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [29/30], Loss: 0.0001 , Acc : 0.9922\n","Val_loss: 0.0004, Val_Acc: 0.9799\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:28<00:00, 33.04it/s]\n","100%|██████████| 238/238 [00:03<00:00, 76.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [30/30], Loss: 0.0001 , Acc : 0.9946\n","Val_loss: 0.0004, Val_Acc: 0.9797\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":null},{"cell_type":"code","source":["best_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh1N0w1cku3O","executionInfo":{"status":"ok","timestamp":1718634083769,"user_tz":-480,"elapsed":489,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"outputId":"6240df22-d5d0-4bb7-e6e2-9d8ed48d090a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9815862159673813"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["paper_model = Paper_model()  # create an instance of the model\n","paper_model.load_state_dict(torch.load(f'/content/drive/MyDrive/weight_0.9816.pth'))\n","paper_model.eval()"],"metadata":{"id":"o8fNDn2DlD9d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718634744519,"user_tz":-480,"elapsed":361,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"outputId":"6a457467-c31a-492e-c936-e41dbd9b6506"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Paper_model(\n","  (layer1): DeformableConv2d(\n","    (offset_conv): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention1): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=32, out_features=16, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=16, out_features=32, bias=True)\n","      )\n","    )\n","  )\n","  (bn1): LayerNorm((32, 52, 52), eps=1e-05, elementwise_affine=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (layer3): DeformableConv2d(\n","    (offset_conv): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention2): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=64, out_features=32, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=32, out_features=64, bias=True)\n","      )\n","    )\n","  )\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (bn2): LayerNorm((64, 26, 26), eps=1e-05, elementwise_affine=True)\n","  (layer5): DeformableConv2d(\n","    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (layer6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (attention3): CBAM(\n","    (sam): SAM(\n","      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","    )\n","    (cam): CAM(\n","      (linear): Sequential(\n","        (0): Linear(in_features=128, out_features=64, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=64, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (bn3): LayerNorm((128, 13, 13), eps=1e-05, elementwise_affine=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc1): Linear(in_features=128, out_features=8, bias=True)\n",")"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["!pip install thop\n","from thop import profile  # Import the profiler\n","import torch.optim as optim\n","from tqdm import tqdm\n","\n","# 定义损失函数\n","criterion = nn.BCELoss()\n","# 定义优化器\n","optimizer = optim.Adam(paper_model.parameters(), lr=0.001)  # 可以调整学习率\n","\n","def calculate_acc_num(outputs, labels):\n","    acc_num = 0\n","    predicted = (outputs > 0.5).float()\n","    for idx in range(predicted.shape[0]):\n","        if torch.allclose(predicted[idx], labels[idx]):\n","            acc_num += 1\n","    return acc_num\n","\n","def evaluate_model(model, dataloader, device):\n","    model.to(device)\n","    model.eval()\n","\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","\n","    # Assume the first batch to infer the input size for FLOPs calculation\n","    first_batch = next(iter(dataloader))\n","    imgs, _ = first_batch\n","    input_shape = imgs.shape  # Assuming imgs_ori to be representative\n","\n","    # Calculate FLOPs and Parameters\n","    flops, params = profile(model, inputs=(imgs.to(device), ), verbose=False)\n","\n","    # Convert FLOPs to GigaFLOPs and parameters to thousands (K)\n","    flops_in_gflops = flops / 1e9  # Convert from FLOPs to GFLOPs\n","    params_in_k = params / 1e3     # Convert from parameters to thousands\n","\n","    # Print the results formatted as GFLOPs and K\n","    print(f\"FLOPs: {flops_in_gflops:.4f} GFLOPs   Params: {params_in_k:.3f}K\")\n","\n","    for imgs, labels in tqdm(dataloader):\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = model(imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += calculate_acc_num(outputs, labels)\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","    print(f'Val_loss: {val_loss / total_val:.4f}, Val_Acc: {val_acc_num / total_val:.4f}')\n","    return outputs\n","\n","outputs = evaluate_model(paper_model, val_dataloader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"],"metadata":{"id":"EsErreOWTSUz","executionInfo":{"status":"ok","timestamp":1718634849421,"user_tz":-480,"elapsed":83070,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bd24a9f-acfa-4eb3-fac3-05965c16b4fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->thop)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->thop)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->thop)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->thop)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->thop)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->thop)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->thop)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->thop)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->thop)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238\n","FLOPs: 2.7398 GFLOPs   Params: 543.912K\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 238/238 [00:03<00:00, 64.47it/s]"]},{"output_type":"stream","name":"stdout","text":["Val_loss: 0.0004, Val_Acc: 0.9816\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["CLASS_MAPPING = {\n","    \"[0 0 0 0 0 0 0 0]\":0,\n","    \"[1 0 0 0 0 0 0 0]\":1,\n","    \"[0 1 0 0 0 0 0 0]\":2,\n","    \"[0 0 1 0 0 0 0 0]\":3,\n","    \"[0 0 0 1 0 0 0 0]\":4,\n","    \"[0 0 0 0 1 0 0 0]\":5,\n","    \"[0 0 0 0 0 1 0 0]\":6,\n","    \"[0 0 0 0 0 0 1 0]\":7,\n","    \"[0 0 0 0 0 0 0 1]\":8,\n","    \"[1 0 1 0 0 0 0 0]\":9,\n","    \"[1 0 0 1 0 0 0 0]\":10,\n","    \"[1 0 0 0 1 0 0 0]\":11,\n","    \"[1 0 0 0 0 0 1 0]\":12,\n","    \"[0 1 1 0 0 0 0 0]\":13,\n","    \"[0 1 0 1 0 0 0 0]\":14,\n","    \"[0 1 0 0 1 0 0 0]\":15,\n","    \"[0 1 0 0 0 0 1 0]\":16,\n","    \"[0 0 1 0 1 0 0 0]\":17,\n","    \"[0 0 1 0 0 0 1 0]\":18,\n","    \"[0 0 0 1 1 0 0 0]\":19,\n","    \"[0 0 0 1 0 0 1 0]\":20,\n","    \"[0 0 0 0 1 0 1 0]\":21,\n","    \"[1 0 1 0 1 0 0 0]\":22,\n","    \"[1 0 1 0 0 0 1 0]\":23,\n","    \"[1 0 0 1 1 0 0 0]\":24,\n","    \"[1 0 0 1 0 0 1 0]\":25,\n","    \"[1 0 0 0 1 0 1 0]\":26,\n","    \"[0 1 1 0 1 0 0 0]\":27,\n","    \"[0 1 1 0 0 0 1 0]\":28,\n","    \"[0 1 0 1 1 0 0 0]\":29,\n","    \"[0 1 0 1 0 0 1 0]\":30,\n","    \"[0 1 0 0 1 0 1 0]\":31,\n","    \"[0 0 1 0 1 0 1 0]\":32,\n","    \"[0 0 0 1 1 0 1 0]\":33,\n","    \"[1 0 1 0 1 0 1 0]\":34,\n","    \"[1 0 0 1 1 0 1 0]\":35,\n","    \"[0 1 1 0 1 0 1 0]\":36,\n","    \"[0 1 0 1 1 0 1 0]\":37\n","}\n","\n","#%%\n","key = \"[0 1 0 1 1 0 1 0]\"\n","value = CLASS_MAPPING[\"[0 1 0 1 1 0 1 0]\"]\n","print(value)\n","#%%\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def plot_confusion_matrix_and_accuracy(model, dataloader, device, class_mapping):\n","    num_classes = len(class_mapping)\n","    class_labels = [None] * num_classes\n","    for label_str, index in class_mapping.items():\n","        class_labels[index] = str(index)  # Directly use the numerical identifier\n","\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for imgs, labels in tqdm(dataloader):\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(imgs)\n","            predicted = (outputs > 0.5).float()\n","\n","            for i in range(labels.size(0)):\n","                label_vec = labels[i].to(torch.uint8).tolist()\n","                label_str = '[' + ' '.join(map(str, label_vec)) + ']'\n","                class_idx = class_mapping[label_str]\n","\n","                pred_vec = predicted[i].tolist()\n","                pred_str = '[' + ' '.join(str(int(p)) for p in pred_vec) + ']'\n","                pred_idx = class_mapping.get(pred_str, -1)  # Handle unseen/misformatted predictions\n","\n","                all_labels.append(class_idx)\n","                all_predictions.append(pred_idx)\n","\n","    # Compute the confusion matrix\n","    conf_mat = confusion_matrix(all_labels, all_predictions, labels=range(len(class_mapping)))\n","\n","    # # Plotting the confusion matrix\n","    # plt.figure(figsize=(15, 13))  # Increase figure size\n","    # ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","    # plt.title('Confusion Matrix', size=20)  # Increase title font size\n","    # plt.ylabel('True Label', size=18)  # Increase y-axis label font size\n","    # plt.xlabel('Predicted Label', size=18)  # Increase x-axis label font size\n","\n","    # # Improve layout to prevent cut-off issues\n","    # plt.xticks(rotation=90, size=10)  # Rotate x labels for better fit, adjust size as needed\n","    # plt.yticks(size=10)  # Adjust y labels size as needed\n","    # plt.tight_layout()  # This adjusts subplot params so that the subplot(s) fits in to the figure area\n","\n","    # plt.show()\n","\n","    # Printing classification report\n","    print(classification_report(\n","        all_labels,\n","        all_predictions,\n","        target_names=class_labels,\n","        labels=range(len(class_labels))  # Ensure it considers all classes\n","    ))\n","\n","    # Calculate and print class-specific accuracy\n","    class_accuracy = 100 * conf_mat.diagonal() / conf_mat.sum(axis=1)\n","    for i, accuracy in enumerate(class_accuracy):\n","        if not np.isnan(accuracy):\n","            print(f'Accuracy of class {class_labels[i]} : {accuracy:.2f}%')\n","        else:\n","            print(f'No samples for class {class_labels[i]}')\n","\n","# Call the function\n","plot_confusion_matrix_and_accuracy(paper_model, val_dataloader, device, CLASS_MAPPING)"],"metadata":{"id":"X0cNDXq0TTvG","executionInfo":{"status":"ok","timestamp":1718634903077,"user_tz":-480,"elapsed":4692,"user":{"displayName":"侯登耀","userId":"10025409286896515993"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"240992ec-ab0b-4610-a026-859f53dd429b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["37\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 238/238 [00:02<00:00, 94.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       194\n","           1       0.98      0.99      0.98       222\n","           2       0.97      1.00      0.99       210\n","           3       0.99      0.98      0.99       180\n","           4       0.98      0.99      0.99       248\n","           5       0.99      0.98      0.98       193\n","           6       1.00      1.00      1.00        24\n","           7       0.98      0.97      0.97       174\n","           8       1.00      0.96      0.98       175\n","           9       0.99      0.98      0.98       214\n","          10       0.98      1.00      0.99       203\n","          11       0.97      0.98      0.98       189\n","          12       0.99      0.99      0.99       202\n","          13       0.99      0.97      0.98       215\n","          14       0.97      1.00      0.99       211\n","          15       0.98      0.97      0.97       203\n","          16       0.98      1.00      0.99       212\n","          17       0.96      0.99      0.98       194\n","          18       0.98      0.99      0.98       194\n","          19       0.99      1.00      0.99       212\n","          20       0.99      1.00      0.99       228\n","          21       0.95      0.97      0.96       191\n","          22       0.98      0.98      0.98       201\n","          23       0.99      0.99      0.99       384\n","          24       0.97      0.98      0.98       197\n","          25       0.98      1.00      0.99       179\n","          26       0.97      0.97      0.97       201\n","          27       0.97      0.99      0.98       206\n","          28       0.98      0.98      0.98       167\n","          29       1.00      0.99      0.99       192\n","          30       0.97      0.98      0.98       192\n","          31       0.99      0.96      0.97       210\n","          32       0.99      0.94      0.97       213\n","          33       0.98      0.99      0.99       198\n","          34       0.98      0.95      0.97       202\n","          35       0.99      0.97      0.98       187\n","          36       0.99      0.96      0.97       191\n","          37       0.99      0.98      0.98       195\n","\n","   micro avg       0.98      0.98      0.98      7603\n","   macro avg       0.98      0.98      0.98      7603\n","weighted avg       0.98      0.98      0.98      7603\n","\n","Accuracy of class 0 : 100.00%\n","Accuracy of class 1 : 99.10%\n","Accuracy of class 2 : 100.00%\n","Accuracy of class 3 : 97.78%\n","Accuracy of class 4 : 98.79%\n","Accuracy of class 5 : 97.93%\n","Accuracy of class 6 : 100.00%\n","Accuracy of class 7 : 97.13%\n","Accuracy of class 8 : 98.25%\n","Accuracy of class 9 : 97.66%\n","Accuracy of class 10 : 100.00%\n","Accuracy of class 11 : 97.88%\n","Accuracy of class 12 : 98.51%\n","Accuracy of class 13 : 97.21%\n","Accuracy of class 14 : 100.00%\n","Accuracy of class 15 : 96.55%\n","Accuracy of class 16 : 100.00%\n","Accuracy of class 17 : 98.97%\n","Accuracy of class 18 : 98.97%\n","Accuracy of class 19 : 99.53%\n","Accuracy of class 20 : 99.56%\n","Accuracy of class 21 : 96.86%\n","Accuracy of class 22 : 97.51%\n","Accuracy of class 23 : 99.48%\n","Accuracy of class 24 : 98.48%\n","Accuracy of class 25 : 100.00%\n","Accuracy of class 26 : 97.01%\n","Accuracy of class 27 : 98.54%\n","Accuracy of class 28 : 97.60%\n","Accuracy of class 29 : 99.48%\n","Accuracy of class 30 : 98.44%\n","Accuracy of class 31 : 96.19%\n","Accuracy of class 32 : 94.37%\n","Accuracy of class 33 : 98.99%\n","Accuracy of class 34 : 95.05%\n","Accuracy of class 35 : 96.79%\n","Accuracy of class 36 : 95.81%\n","Accuracy of class 37 : 97.95%\n"]}]}]}