{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkNxDmZ40SHk","executionInfo":{"status":"ok","timestamp":1714361994545,"user_tz":-480,"elapsed":27859,"user":{"displayName":"Theovin Lautan","userId":"17106006947934370905"}},"outputId":"63d9739e-5d7f-448f-faab-cb6108b570cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJR8bAycY_3Z"},"outputs":[],"source":["import torch\n","import torchvision.ops\n","from torch import nn\n","\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 dilation=1,\n","                 bias=False):\n","        super(DeformableConv2d, self).__init__()\n","\n","        assert type(kernel_size) == tuple or type(kernel_size) == int\n","\n","        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n","        self.stride = stride if type(stride) == tuple else (stride, stride)\n","        self.padding = padding\n","        self.dilation = dilation\n","\n","        self.offset_conv = nn.Conv2d(in_channels,\n","                                     2 * kernel_size[0] * kernel_size[1],\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     dilation=self.dilation,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","\n","        self.modulator_conv = nn.Conv2d(in_channels,\n","                                        1 * kernel_size[0] * kernel_size[1],\n","                                        kernel_size=kernel_size,\n","                                        stride=stride,\n","                                        padding=self.padding,\n","                                        dilation=self.dilation,\n","                                        bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      dilation=self.dilation,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        # h, w = x.shape[2:]\n","        # max_offset = max(h, w)/4.\n","\n","        offset = self.offset_conv(x)  # .clamp(-max_offset, max_offset)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","        # op = (n - (k * d - 1) + 2p / s)\n","        x = torchvision.ops.deform_conv2d(input=x,\n","                                          offset=offset,\n","                                          weight=self.regular_conv.weight,\n","                                          bias=self.regular_conv.bias,\n","                                          padding=self.padding,\n","                                          mask=modulator,\n","                                          stride=self.stride,\n","                                          dilation=self.dilation)\n","        return x"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Paper_model(nn.Module):\n","    def __init__(self,classes=8, conv_num=32):\n","        super(Paper_model, self).__init__()\n","\n","        self.conv_num = conv_num\n","\n","        self.conv_1 = nn.Conv2d(1, conv_num, kernel_size=5, stride=2, padding=2)\n","        self.bn_1 = nn.BatchNorm2d(conv_num)\n","\n","        self.conv_2 = nn.Conv2d(conv_num, conv_num * 2, kernel_size=3, stride=2, padding=1)\n","        self.dc_1 = DeformableConv2d(conv_num * 2, conv_num * 2)\n","        self.bn_2 = nn.BatchNorm2d(conv_num * 2)\n","\n","        self.conv_3 = nn.Conv2d(conv_num * 2, conv_num * 4, kernel_size=3, stride=2, padding=1)\n","        self.dc_2 = DeformableConv2d(conv_num * 4, conv_num * 4)\n","        self.bn_3 = nn.BatchNorm2d(conv_num * 4)\n","\n","        self.conv_4 = nn.Conv2d(conv_num * 4, conv_num * 4, kernel_size=3, stride=2, padding=1)\n","        self.dc_3 = DeformableConv2d(conv_num * 4, conv_num * 4)\n","        self.bn_4 = nn.BatchNorm2d(conv_num * 4)\n","\n","        self.fc_1 = nn.Linear(conv_num * 4 * (4 * 4), conv_num * 4)\n","        self.fc_2 = nn.Linear(conv_num * 4, classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn_1(self.conv_1(x)))\n","\n","        x = F.relu(self.bn_2(self.dc_1(self.conv_2(x))))\n","\n","        x = F.relu(self.bn_3(self.dc_2(self.conv_3(x))))\n","\n","        x = F.relu(self.bn_4(self.dc_3(self.conv_4(x))))\n","\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc_1(x))\n","        x = torch.sigmoid(self.fc_2(x))\n","\n","        return x"],"metadata":{"id":"QezBSWfrbGfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["you = DeformableConv2d(1,50)\n","print(you.forward(torch.randn(1,1,52,52)).shape)\n","x = torch.randn(10,1,52,52)\n","print(type(x))\n","test = Paper_model()\n","print(test.forward(x).shape)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV_uiFEbZXGz","executionInfo":{"status":"ok","timestamp":1714362015339,"user_tz":-480,"elapsed":848,"user":{"displayName":"Theovin Lautan","userId":"17106006947934370905"}},"outputId":"2a1a0d1a-6ccc-4bb3-a22e-c4db69fd1737"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 50, 52, 52])\n","<class 'torch.Tensor'>\n","torch.Size([10, 8])\n","Paper_model(\n","  (conv_1): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (dc_1): DeformableConv2d(\n","    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (dc_2): DeformableConv2d(\n","    (offset_conv): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (bn_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (dc_3): DeformableConv2d(\n","    (offset_conv): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (modulator_conv): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (regular_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (bn_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc_1): Linear(in_features=2048, out_features=128, bias=True)\n","  (fc_2): Linear(in_features=128, out_features=8, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","class WaferDataset(Dataset):\n","    def __init__(self, img_array, label_array):\n","        self.img_array = img_array\n","        self.label_array = label_array\n","\n","    def __len__(self):\n","        return len(self.img_array)\n","\n","    def __getitem__(self, idx):\n","        img = torch.from_numpy(self.img_array[idx]).float().unsqueeze(0)  # 转换为 PyTorch 张量\n","        label = torch.from_numpy(self.label_array[idx]).float()  # 转换为 PyTorch 张量\n","        return img, label\n","\n","# 加载数据\n","data = np.load('/content/drive/MyDrive/Courses/DL/DeepLearning_project/Dataset/Wafer_Map_Datasets.npz')\n","img_array = data['arr_0']\n","label_array = data['arr_1']\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 设置划分比例\n","val_split = 0.2\n","dataset_size = len(wafer_dataset)\n","indices = list(range(dataset_size))\n","np.random.shuffle(indices)\n","val_size = int(np.floor(val_split * dataset_size))\n","train_indices, val_indices = indices[val_size:], indices[:val_size]\n","\n","# 创建训练集和验证集的 SubsetRandomSampler\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","# 创建数据加载器\n","batch_size = 32\n","train_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_dataloader = DataLoader(wafer_dataset, batch_size=batch_size, sampler=val_sampler)\n"],"metadata":{"id":"HDItKcRaga9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# 创建数据集\n","wafer_dataset = WaferDataset(img_array, label_array)\n","\n","# 创建数据加载器\n","batch_size = 32\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","\n","# 使用数据加载器进行训练\n","# 创建模型实例\n","paper_model = Paper_model()\n","\n","# 定义损失函数\n","criterion = nn.BCELoss()\n","\n","# 定义优化器\n","optimizer = optim.Adam(paper_model.parameters(), lr=0.001)  # 可以调整学习率\n","\n","\n","num_epochs = 10\n","# 检查是否有可用的 GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# 将模型移动到设备上\n","paper_model.to(device)\n","\n","# 加载数据集的代码\n","\n","# 创建数据加载器，并将数据移动到设备上\n","dataloader = DataLoader(wafer_dataset, batch_size=batch_size, shuffle=True)\n","dataloader = [(imgs.to(device), labels.to(device)) for imgs, labels in dataloader]\n","\n","import random\n","from tqdm import tqdm\n","def caculate_acc_num(outputs,labels):\n","  acc_num = 0\n","  predicted = (outputs > 0.5).float()\n","  #print(outputs.shape)\n","  for idx in range(predicted.shape[0]):\n","    #print(\"Predicted : \",predicted[idx])\n","    #print(\"Labels : \",labels[idx])\n","    if torch.allclose(predicted[idx], labels[idx]):\n","      acc_num += 1\n","\n","  return acc_num\n","# 使用数据加载器进行训练\n","for epoch in range(num_epochs):\n","    train_acc_num = 0\n","    total_train = 0\n","    train_loss = 0\n","    for imgs, labels in tqdm(train_dataloader):\n","        # 清除梯度\n","        optimizer.zero_grad()\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # 前向传播\n","        outputs = paper_model(imgs)\n","        total_train += imgs.shape[0]\n","        train_acc_num += caculate_acc_num(outputs,labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        train_loss += loss.item()\n","        # 反向传播\n","        loss.backward()\n","\n","        # 更新权重\n","        optimizer.step()\n","        # 随机选择一笔数据打印其标签和预测值\n","        #idx = random.randint(0, len(labels) - 1)\n","        #print(f'Label: {labels[idx]}, Prediction: {(outputs[idx] > 0.5).float()}')\n","\n","    val_acc_num = 0\n","    total_val = 0\n","    val_loss = 0\n","    for imgs, labels in tqdm(val_dataloader):\n","        # 前向传播\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        outputs = paper_model(imgs)\n","        total_val += imgs.shape[0]\n","        val_acc_num += caculate_acc_num(outputs, labels)\n","        # 计算损失\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","\n","    # 每个 epoch 结束后打印损失\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {(train_loss/total_train):.4f} , Acc : {(train_acc_num/total_train):.4f}')\n","    print(f'Val_loss: {(val_loss/total_val):.4f}, Val_Acc: {(val_acc_num/total_val):.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWekxgQp5I0T","executionInfo":{"status":"ok","timestamp":1714362213121,"user_tz":-480,"elapsed":170061,"user":{"displayName":"Theovin Lautan","userId":"17106006947934370905"}},"outputId":"8d7735cb-ed89-43f1-acd1-5aa75048cd0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:16<00:00, 59.08it/s]\n","100%|██████████| 238/238 [00:02<00:00, 107.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.0040 , Acc : 0.7118\n","Val_loss: 0.0024, Val_Acc: 0.8223\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 63.60it/s]\n","100%|██████████| 238/238 [00:02<00:00, 109.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/10], Loss: 0.0029 , Acc : 0.7862\n","Val_loss: 0.0018, Val_Acc: 0.8799\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 67.88it/s]\n","100%|██████████| 238/238 [00:02<00:00, 108.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/10], Loss: 0.0017 , Acc : 0.8827\n","Val_loss: 0.0013, Val_Acc: 0.9149\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 65.66it/s]\n","100%|██████████| 238/238 [00:02<00:00, 87.77it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/10], Loss: 0.0016 , Acc : 0.8871\n","Val_loss: 0.0018, Val_Acc: 0.8774\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 66.66it/s]\n","100%|██████████| 238/238 [00:02<00:00, 108.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/10], Loss: 0.0014 , Acc : 0.9061\n","Val_loss: 0.0013, Val_Acc: 0.9154\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 66.30it/s]\n","100%|██████████| 238/238 [00:02<00:00, 111.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/10], Loss: 0.0013 , Acc : 0.9140\n","Val_loss: 0.0010, Val_Acc: 0.9352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 67.03it/s]\n","100%|██████████| 238/238 [00:02<00:00, 96.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/10], Loss: 0.0011 , Acc : 0.9282\n","Val_loss: 0.0013, Val_Acc: 0.9204\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 66.01it/s]\n","100%|██████████| 238/238 [00:02<00:00, 103.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/10], Loss: 0.0009 , Acc : 0.9424\n","Val_loss: 0.0011, Val_Acc: 0.9356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 66.96it/s]\n","100%|██████████| 238/238 [00:02<00:00, 102.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/10], Loss: 0.0009 , Acc : 0.9436\n","Val_loss: 0.0011, Val_Acc: 0.9313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 951/951 [00:14<00:00, 67.88it/s]\n","100%|██████████| 238/238 [00:02<00:00, 111.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Loss: 0.0009 , Acc : 0.9439\n","Val_loss: 0.0009, Val_Acc: 0.9455\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}